{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### DATASET PROCESSING ####################################\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from numpy import genfromtxt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "REBUILD_DATA = True\n",
    "maxAX=1.997222249219917\n",
    "minAX=-0.4888889218044315\n",
    "maxAY=1.634722245672321\n",
    "minAY=-1.252777853006882\n",
    "maxAZ=1.463888933022928\n",
    "minAZ=-0.7916666716198171\n",
    "maxGX=5.320330619812012\n",
    "minGX=-3.276986598968506\n",
    "maxGY=3.133127927780151\n",
    "minGY=-4.782769203186035\n",
    "maxGZ=1.985922932624817\n",
    "minGZ=-2.441933870315552\n",
    "\n",
    "\n",
    "class HAR():\n",
    "    \n",
    "    labels = []\n",
    "    j= 0 #to loop over labels file \n",
    "    exp_user =[]\n",
    "    sample = [] # to put all six readings then add in the big list (all_data)\n",
    "    sample_label=[] # to add the sample array and label in one array\n",
    "    \n",
    "    \n",
    "    text_path = 'labels.txt'\n",
    "    exp_id = []\n",
    "    user_id = []\n",
    "    act_id = []\n",
    "    beg_id = []\n",
    "    end_id = []\n",
    "    \n",
    "    ######### FOR NORMALIZATION #########\n",
    "    total = 19082*3\n",
    "    sum=0\n",
    "    mean=0\n",
    "    std=0\n",
    "   \n",
    "    \n",
    "\n",
    "    test_user_ids = [2, 4, 9, 10, 12, 13, 18, 20, 24];   #check for those ids for test data\n",
    "    # for train data\n",
    "    acc_x =[]\n",
    "    acc_y =[]\n",
    "    acc_z =[]\n",
    "\n",
    "    gyro_x =[]\n",
    "    gyro_y =[]\n",
    "    gyro_z =[]\n",
    "\n",
    "    exp_user = []  \n",
    "    # for test data\n",
    "    t_acc_x =[]\n",
    "    t_acc_y =[]\n",
    "    t_acc_z =[]\n",
    "    t_gyro_x =[]\n",
    "    t_gyro_y =[]\n",
    "    t_gyro_z =[]\n",
    "    # for putting all data after reading from files abl ma a2semha to training and testing\n",
    "    all_x = []\n",
    "    all_y = []\n",
    "    all_z = []\n",
    "    all_gx = []\n",
    "    all_gy = []\n",
    "    all_gz = []\n",
    "    values = []\n",
    "   \n",
    "    labels = []\n",
    "    test_labels = []\n",
    "\n",
    "    all_data = []\n",
    "    test_all_data = []\n",
    "    segment_size = 128 # how many samples in each segment\n",
    "    \n",
    "    ax_data=[]\n",
    "    ay_data=[]\n",
    "    az_data=[]\n",
    "    gx_data=[]\n",
    "    gy_data=[]\n",
    "    gz_data=[]\n",
    "    \n",
    "    \n",
    "    ax_test_data=[]\n",
    "    ay_test_data=[]\n",
    "    az_test_data=[]\n",
    "    gx_test_data=[]\n",
    "    gy_test_data=[]\n",
    "    gz_test_data=[]\n",
    "    \n",
    "    \n",
    "    \n",
    "    def data_processing(self):\n",
    "        with open(self.text_path) as f:\n",
    "            text_data = f.readlines()\n",
    "            for line_index in range(len(text_data)):\n",
    "                line = text_data[line_index].strip('\\n')\n",
    "                words = line.split()\n",
    "                self.exp_id.append(words[0])\n",
    "                self.user_id.append(words[1])\n",
    "                self.act_id.append(words[2])\n",
    "                self.beg_id.append(words[3])\n",
    "                self.end_id.append(int(words[4],10))\n",
    "                self.exp_user.append((words[0],words[1]))  #pairs of exp and user ids\n",
    "        self.exp_user = list(dict.fromkeys(self.exp_user))\n",
    "        for i in range(len(self.exp_user)):  # loop over the files (experiments)\n",
    "            self.all_x = []\n",
    "            self.all_y = []\n",
    "            self.all_z = []          #RESET\n",
    "            self.all_gx = []\n",
    "            self.all_gy = []\n",
    "            self.all_gz = []\n",
    "            if(int(self.exp_user[i][0],10))<10:\n",
    "                acc_path = 'acc_exp0'+ self.exp_user[i][0]\n",
    "                gyro_path = 'gyro_exp0'+ self.exp_user[i][0]\n",
    "            else:\n",
    "                acc_path = 'acc_exp'+ self.exp_user[i][0]\n",
    "                gyro_path = 'gyro_exp'+ self.exp_user[i][0]\n",
    "                \n",
    "            if(int(self.exp_user[i][1],10))<10:\n",
    "                acc_path = acc_path+'_user0'+ self.exp_user[i][1]+'.txt'\n",
    "                gyro_path = gyro_path+'_user0'+ self.exp_user[i][1]+'.txt'\n",
    "                \n",
    "            else:\n",
    "                acc_path = acc_path+'_user'+ self.exp_user[i][1]+'.txt'\n",
    "                gyro_path = gyro_path+'_user'+ self.exp_user[i][1]+'.txt'\n",
    "                \n",
    "            with open(acc_path) as f: #open acc file and put all the content in all_x\n",
    "                text_data = f.readlines()\n",
    "                for line_index in range(len(text_data)):\n",
    "                    line = text_data[line_index].strip('\\n')\n",
    "                    words = line.split()\n",
    "                    ########## NORMALIZE DATA ########\n",
    "                    \n",
    "                    accX = (float(words[0]) - minAX) / (maxAX - minAX)\n",
    "                    accY = (float(words[1]) - minAY) / (maxAY - minAY)\n",
    "                    accZ = (float(words[2]) - minAZ) / (maxAZ - minAZ)\n",
    "                    self.all_x.append(accX)\n",
    "                    self.all_y.append(accY)\n",
    "                    self.all_z.append(accZ)\n",
    "                    \n",
    "                    \n",
    "            with open(gyro_path) as f: #open gyro file and put all the content in all_gx\n",
    "                text_data = f.readlines() \n",
    "                for line_index in range(len(text_data)): \n",
    "                    line = text_data[line_index].strip('\\n')\n",
    "                    words = line.split()\n",
    "                    ########## NORMALIZE DATA ########\n",
    "                    \n",
    "                    gyroX = (float(words[0]) - minGX) / (maxGX - minGX)\n",
    "                    gyroY = (float(words[1]) - minGY) / (maxGY - minGY)\n",
    "                    gyroZ = (float(words[2]) - minGZ) / (maxGZ - minGZ)\n",
    "                    self.all_gx.append(gyroX)\n",
    "                    self.all_gy.append(gyroY)\n",
    "                    self.all_gz.append(gyroZ)\n",
    "                   \n",
    "        \n",
    "            while (self.j<1214) and (self.exp_user[i][0]== self.exp_id[self.j]) and (self.exp_user[i][1]== self.user_id[self.j]):\n",
    "                k = int(self.beg_id[self.j],10)-1\n",
    "                sampleAX=[]\n",
    "                sampleAY=[]\n",
    "                sampleAZ=[]\n",
    "                sampleGX=[]\n",
    "                sampleGY=[]\n",
    "                sampleGZ=[]\n",
    "               \n",
    "                if int(self.act_id[self.j],10)<7:# only take first 6 labels\n",
    "                    while k+self.segment_size<=self.end_id[self.j]:# start the new segment\n",
    "                        b = k\n",
    "                        while b <k+self.segment_size: # fill up the segment\n",
    "                            sampleAX.append(float(self.all_x[b]))\n",
    "                            sampleAY.append(float(self.all_y[b]))\n",
    "                            sampleAZ.append(float(self.all_z[b]))\n",
    "                            sampleGX.append(float(self.all_gx[b]))\n",
    "                            sampleGY.append(float(self.all_gy[b]))\n",
    "                            sampleGZ.append(float(self.all_gz[b]))\n",
    "                            b+=1\n",
    "                            \n",
    "                        if int(self.user_id[self.j],10) in self.test_user_ids: #checking for train or test\n",
    "                           \n",
    "                            #self.sample_label.append(self.values)\n",
    "                            self.test_labels.append(np.eye(6)[int(self.act_id[self.j],10)-1]) #adding label with segment\n",
    "                            \n",
    "                            self.ax_test_data.append(sampleAX)\n",
    "                            self.ay_test_data.append(sampleAY)\n",
    "                            self.az_test_data.append(sampleAZ)\n",
    "                            self.gx_test_data.append(sampleGX)\n",
    "                            self.gy_test_data.append(sampleGY)\n",
    "                            self.gz_test_data.append(sampleGZ)\n",
    "                            \n",
    "                            #print(self.sample_label)\n",
    "                            #print(self.sample_label[0])\n",
    "                            #print(self.sample_label[1])\n",
    "                            #print(len(self.values))\n",
    "                            \n",
    "                        else:\n",
    "                            self.labels.append(np.eye(6)[int(self.act_id[self.j],10)-1]) #adding label with segment\n",
    "                            \n",
    "                            self.ax_data.append(sampleAX)\n",
    "                            self.ay_data.append(sampleAY)\n",
    "                            self.az_data.append(sampleAZ)\n",
    "                            self.gx_data.append(sampleGX)\n",
    "                            self.gy_data.append(sampleGY)\n",
    "                            self.gz_data.append(sampleGZ)\n",
    "                            \n",
    "                            \n",
    "                        sampleAX = []\n",
    "                        sampleAY = []\n",
    "                        sampleAZ = []\n",
    "                        sampleGX = []\n",
    "                        sampleGY = []\n",
    "                        sampleGZ = []    \n",
    "                        \n",
    "                        k = k+self.segment_size # to start where the last segment ended\n",
    "                        self.sample = []\n",
    "                        self.sample_label = []\n",
    "                        self.values = []\n",
    "                        \n",
    "                self.j+=1\n",
    "        \n",
    "        \n",
    "        #print(len(self.test_labels))\n",
    "        # SHUFFLING SEGMENTS\n",
    "        #np.random.shuffle(self.all_data)\n",
    "        #np.random.shuffle(self.test_all_data)\n",
    "        np.save(\"training_data_ax.npy\",self.ax_data)\n",
    "        np.save(\"training_data_ay.npy\",self.ay_data)\n",
    "        np.save(\"training_data_az.npy\",self.az_data)\n",
    "        \n",
    "        np.save(\"training_data_gx.npy\",self.gx_data)\n",
    "        np.save(\"training_data_gy.npy\",self.gy_data)\n",
    "        np.save(\"training_data_gz.npy\",self.gz_data)\n",
    "        \n",
    "        np.save(\"training_labels.npy\",self.labels)\n",
    "        \n",
    "        \n",
    "        \n",
    "        np.save(\"testing_data_ax.npy\",self.ax_test_data)\n",
    "        np.save(\"testing_data_ay.npy\",self.ay_test_data)\n",
    "        np.save(\"testing_data_az.npy\",self.az_test_data)\n",
    "        \n",
    "        np.save(\"testing_data_gx.npy\",self.gx_test_data)\n",
    "        np.save(\"testing_data_gy.npy\",self.gy_test_data)\n",
    "        np.save(\"testing_data_gz.npy\",self.gz_test_data)\n",
    "        \n",
    "        \n",
    "        np.save(\"testing_labels.npy\",self.test_labels)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #REBUILD_DATA = False\n",
    "        #print(self.all_data[0])\n",
    "\n",
    "        \n",
    "     \n",
    "        \n",
    "      \n",
    "\n",
    "        \n",
    "       \n",
    "                \n",
    "       \n",
    "\n",
    "if REBUILD_DATA:\n",
    "    \n",
    "    HAR = HAR()\n",
    "    HAR.data_processing()\n",
    "   \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
